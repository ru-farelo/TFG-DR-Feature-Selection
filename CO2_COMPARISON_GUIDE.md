# ğŸŒ± GuÃ­a para Comparar Consumo CO2 entre MÃ©todos

## ğŸ¯ Objetivo

Comparar el consumo de CO2 de diferentes configuraciones del pipeline:

1. **MÃ©todo original** (sin optimizaciones)
2. **Fast-MRMR** (selecciÃ³n rÃ¡pida de caracterÃ­sticas)
3. **PU Learning** (aprendizaje con ejemplos no etiquetados)
4. **Fast + PU** (combinaciÃ³n de ambos)

## ğŸ“Š MÃ©tricas Subidas a Neptune

### Estructura Simplificada

```
co2/
â”œâ”€â”€ phases/
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ mean_per_fold_g          # Promedio de CO2 por fold (eficiencia)
â”‚   â”‚   â””â”€â”€ total_experiment_g       # Total del experimento (coste absoluto)
â”‚   â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ pu_preprocessing/            # Solo si usas PU Learning
â”‚   â”œâ”€â”€ fast_mrmr/                   # Solo si usas Fast-MRMR
â”‚   â”œâ”€â”€ bagging/                     # Solo si usas Bagging
â”‚   â””â”€â”€ hyperparameter_tuning/
â”œâ”€â”€ total_experiment_g               # Total de todas las fases
â””â”€â”€ total_experiment_kg              # Total en kilogramos
```

## ğŸš€ CÃ³mo Ejecutar Experimentos para Comparar

### 1ï¸âƒ£ MÃ©todo Original (Baseline)

```powershell
python .\code\main.py `
    --dataset GO `
    --classifier BRF `
    --carbon_tracking `
    --neptune
```

**Fases medidas**: `training`, `inference`, `hyperparameter_tuning`

### 2ï¸âƒ£ MÃ©todo con Fast-MRMR

```powershell
python .\code\main.py `
    --dataset GO `
    --classifier BRF `
    --fast_mrmr `
    --fast_mrmr_k 50% `
    --carbon_tracking `
    --neptune
```

**Fases medidas**: `fast_mrmr`, `training`, `inference`, `hyperparameter_tuning`

### 3ï¸âƒ£ MÃ©todo con PU Learning

```powershell
python .\code\main.py `
    --dataset GO `
    --classifier BRF `
    --pu_learning similarity `
    --carbon_tracking `
    --neptune
```

**Fases medidas**: `pu_preprocessing`, `training`, `inference`, `hyperparameter_tuning`

### 4ï¸âƒ£ MÃ©todo Fast + PU

```powershell
python .\code\main.py `
    --dataset GO `
    --classifier BRF `
    --fast_mrmr `
    --fast_mrmr_k 50% `
    --pu_learning similarity `
    --carbon_tracking `
    --neptune
```

**Fases medidas**: `fast_mrmr`, `pu_preprocessing`, `training`, `inference`, `hyperparameter_tuning`

## ğŸ“ˆ InterpretaciÃ³n de MÃ©tricas

### `mean_per_fold_g` - Eficiencia por fold

**Pregunta**: Â¿CuÃ¡nto CO2 consume en promedio cada fold?

**Ejemplo**:
```
training/mean_per_fold_g = 2.456g
```
Significa que cada fold de entrenamiento emite ~2.5g de CO2.

**Para comparar**:
- âœ… Menor = mÃ¡s eficiente
- âš ï¸ Medir en la misma mÃ¡quina y condiciones

### `total_experiment_g` - Coste absoluto total

**Pregunta**: Â¿CuÃ¡nto CO2 costÃ³ toda la fase en el experimento completo?

**Ejemplo**:
```
training/total_experiment_g = 245.6g
```
Con 10 seeds Ã— 10 folds = 100 entrenamientos, el total fue 245.6g.

**Para comparar**:
- âœ… Menor = menos coste absoluto
- ğŸ“Š Multiplicar por nÃºmero de experimentos para estimar coste a largo plazo

## ğŸ” Preguntas que Puedes Responder

### Â¿Fast-MRMR reduce el coste de training?

Compara:
- MÃ©todo Original: `training/mean_per_fold_g`
- Con Fast-MRMR: `training/mean_per_fold_g`

Si Fast-MRMR reduce features de 5000 â†’ 500, el training deberÃ­a ser mÃ¡s rÃ¡pido y emitir menos.

**Pero tambiÃ©n mira**:
- `fast_mrmr/total_experiment_g` - Â¿El coste de selecciÃ³n compensa el ahorro?

### Â¿PU Learning vale la pena en tÃ©rminos de CO2?

Compara:
- MÃ©todo Original: `total_experiment_g`
- Con PU: `total_experiment_g`

El PU aÃ±ade `pu_preprocessing` pero puede mejorar mÃ©tricas. Pregunta:
- **Â¿El coste extra justifica la mejora en F1/AUC?**

### Â¿QuÃ© fase consume mÃ¡s?

Mira `co2/phases/*/total_experiment_g` y ordena de mayor a menor.

TÃ­picamente:
1. `training` (mayor)
2. `hyperparameter_tuning` 
3. `pu_preprocessing` (si aplica)
4. `fast_mrmr` (si aplica)
5. `inference` (menor)

### Â¿CuÃ¡l es el mÃ©todo mÃ¡s sostenible?

Compara `co2/total_experiment_kg` de los 4 mÃ©todos.

**Considera tambiÃ©n**:
- MÃ©tricas de ML (F1, AUC, Precision, Recall)
- Trade-off: menor CO2 vs mejor rendimiento

## ğŸ“Š Ejemplo de ComparaciÃ³n

### Salida en Consola

```
======================================================================
ğŸŒ± CARBON EMISSIONS SUMMARY
======================================================================
  fast_mrmr                 |   0.124g/fold |     12.450g total
  pu_preprocessing          |   0.893g/fold |     89.320g total
  training                  |   1.456g/fold |    145.600g total
  inference                 |   0.023g/fold |      2.340g total
  hyperparameter_tuning     |   3.200g/fold |    320.000g total
----------------------------------------------------------------------
  TOTAL EXPERIMENT          |               |    569.710g (0.5697 kg)
======================================================================
```

### En Neptune

Navega a `co2/phases/` y compara entre runs:

| MÃ©todo | training (g/fold) | total_experiment (g) |
|--------|-------------------|----------------------|
| Original | 2.456 | 245.6 |
| Fast-MRMR | 1.456 | 145.6 |
| PU Learning | 2.234 | 223.4 |
| Fast + PU | 1.389 | 138.9 |

**ConclusiÃ³n**: Fast + PU es el mÃ¡s eficiente (menor CO2 por fold y menor coste total).

## ğŸ“ Buenas PrÃ¡cticas

### Para comparaciones justas

1. âœ… **Misma mÃ¡quina**: El hardware afecta las mediciones
2. âœ… **Mismos seeds**: Usa los mismos SEEDS para todos los mÃ©todos
3. âœ… **Mismas condiciones**: CPU load, temperatura ambiente, etc.
4. âœ… **Mismo dataset**: GO, PathDip, etc.
5. âœ… **Mismo clasificador**: BRF, CAT, XGB

### Para reportar en tu TFG

- **Tabla comparativa** de `mean_per_fold_g` por fase y mÃ©todo
- **GrÃ¡fico de barras** de `total_experiment_g` por mÃ©todo
- **Trade-off plot**: CO2 vs F1-Score (Â¿mÃ¡s sostenible = peor rendimiento?)
- **Porcentaje de reducciÃ³n**: "Fast-MRMR reduce el coste en un 40.6%"

### Contextualizar las emisiones

- 1g de CO2 â‰ˆ cargar un smartphone 1 vez
- 100g de CO2 â‰ˆ conducir un coche 500 metros
- 1kg de CO2 â‰ˆ volar 5 kilÃ³metros en aviÃ³n

Ejemplo: "Nuestro mÃ©todo Fast+PU emite 138.9g por experimento completo, equivalente a cargar ~139 smartphones."

## ğŸ”§ Comandos Ãštiles

### Ejecutar los 4 mÃ©todos en secuencia

```powershell
# 1. Baseline
python .\code\main.py --dataset GO --classifier BRF --carbon_tracking --neptune

# 2. Fast-MRMR
python .\code\main.py --dataset GO --classifier BRF --fast_mrmr --fast_mrmr_k 50% --carbon_tracking --neptune

# 3. PU Learning
python .\code\main.py --dataset GO --classifier BRF --pu_learning similarity --carbon_tracking --neptune

# 4. Fast + PU
python .\code\main.py --dataset GO --classifier BRF --fast_mrmr --fast_mrmr_k 50% --pu_learning similarity --carbon_tracking --neptune
```

### Comparar en Neptune

1. Ve a tu proyecto Neptune
2. Navega a `co2/phases/training/mean_per_fold_g`
3. Compara runs con "Compare" view
4. Exporta a CSV o genera grÃ¡ficos

## âœ… Checklist para tu TFG

- [ ] Ejecutar los 4 mÃ©todos con `--carbon_tracking`
- [ ] Recolectar datos de Neptune en tabla CSV
- [ ] Crear grÃ¡fico comparativo de consumo por fase
- [ ] Calcular porcentaje de reducciÃ³n de CO2
- [ ] Comparar CO2 vs mÃ©tricas de ML (F1, AUC)
- [ ] Contextualizar emisiones (smartphones, distancia en coche)
- [ ] Discutir trade-offs: eficiencia vs rendimiento
- [ ] ConclusiÃ³n: Â¿cuÃ¡l es el mÃ©todo mÃ¡s sostenible?

Â¡Listo para demostrar que tu mÃ©todo no solo es mejor en mÃ©tricas, sino tambiÃ©n mÃ¡s sostenible! ğŸŒ±
